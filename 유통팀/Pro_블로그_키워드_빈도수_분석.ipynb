{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Pro_블로그 키워드 빈도수 분석.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachkim/PROJECT/blob/master/%EC%9C%A0%ED%86%B5%ED%8C%80/Pro_%EB%B8%94%EB%A1%9C%EA%B7%B8_%ED%82%A4%EC%9B%8C%EB%93%9C_%EB%B9%88%EB%8F%84%EC%88%98_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBnAaa3e4Xc"
      },
      "source": [
        "## 코드 설명\n",
        "- 유명 블로그에서 특정 키워드로 검색했을 때, 몇 건의 결과물이 나오는지 빈도수를 검색하는 함수입니다\n",
        "- 기간을 설정하는 함수와 빈도수를 검색하는 함수는 별도로 구분했습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYUlGdpQXAc"
      },
      "source": [
        "### 1) 필요 라이브러리 다운"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhSCChpjQXAj",
        "outputId": "73e4fca2-1b84-4925-a97a-803c0bb492ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "from datetime import datetime, timedelta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etjn3eXvQXAn"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfXVSZfjQXAq"
      },
      "source": [
        "### 2) 크롤링 연습\n",
        "- 실제 url을 가지고 어떤 항목을 가져와야 빈도수 검색이 가능한지 연습해본 부분입니다\n",
        "- 안 중요하니 스킵스킵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVIdIFYYQXAr"
      },
      "source": [
        "url = 'http://search.daum.net/search?w=blog&f=section&SA=daumsec&lpp=10&nil_profile=vsearch&nil_src=blog&q=%ED%8A%B8%EB%9F%AC%ED%94%8C&DA=STC&period=w&sd=20200918153010&ed=20200925153010'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWKfioGOQXAv"
      },
      "source": [
        "page = requests.get(url)\n",
        "soup = bs(page.text,'html.parser')\n",
        "all = soup.find('span',{'class':'txt_info'})\n",
        "how_many=all.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGFKcAFIQXAy"
      },
      "source": [
        "url = 'http://search.daum.net/search?nil_suggest=btn&w=blog&lpp=10&DA=STC&q={}&sd={}000000&ed={}235959&period=u'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E2ZX26jQXA2"
      },
      "source": [
        "URL = url.format('트러플',20200918,20200925)\n",
        "URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZKlHhyvQXA5"
      },
      "source": [
        "page = requests.get(URL)\n",
        "soup = bs(page.text,'html.parser')\n",
        "all = soup.find('span',{'class':'txt_info'})\n",
        "how_many=all.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkYVZo2GQXA8"
      },
      "source": [
        "how_many"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAalpYmCQXA_"
      },
      "source": [
        "blank = how_many.split('/')[1].replace(\" \",\"\")\n",
        "maybe = blank.replace(\"약\",\"\")\n",
        "number = maybe.replace(\"건\",\"\")\n",
        "nocom = number.replace(\",\",\"\")\n",
        "num = int(nocom)\n",
        "num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E8m7aHBQXBC"
      },
      "source": [
        "### 3) 함수화 진행\n",
        "- x에 검색 키워드, y에 날짜를 지정하면 해당 날짜에 검색 키워드가 등장한 포스팅의 빈도수를 검색해줍니다\n",
        "- 우선 빈도수 검색함수는 하루단위로 작동하게 해놨으나 필요하시면 make_end부분의 timedelta(days=1)을 한 달씩 늘도록 수정하면 됩니다\n",
        "- 다음과 티스토리는 url에서 키워드나 날짜를 입력하는 방식이 동일하기에 코드가 거의 같습니다\n",
        "- 네이버는 입력받는 형식이 달라서 코드가 조금 다르나 작동하는 원리는 같습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPxaPQfvboz4"
      },
      "source": [
        "#티스토리에서 빈도 검색하는 함수\n",
        "def get_tistory_frequency(x,y):\n",
        "    url = 'http://search.daum.net/search?w=blog&f=section&SA=tistory&lpp=10&nil_profile=vsearch&nil_src=blog&q={}&DA=STC&period=u&sd={}000000&ed={}235959'\n",
        "    make_start = pd.to_datetime(str(y), format='%Y%m%d')\n",
        "    make_end = make_start +timedelta(days=1)\n",
        "    z = make_end.strftime(\"%Y%m%d\")\n",
        "    \n",
        "    URL = url.format(x,y,z)\n",
        "    page = requests.get(URL)\n",
        "    time.sleep(1)\n",
        "    \n",
        "    soup = bs(page.text,'html.parser')\n",
        "    time.sleep(1)\n",
        "    \n",
        "    whole = soup.find('div',{'class':'sub_expander'})\n",
        "    find_number = whole.find('span',{'class':'txt_info'})\n",
        "    if find_number is None:\n",
        "        return(0)  \n",
        "    else:\n",
        "        found = find_number.text\n",
        "        split = found.split('/')[1]\n",
        "        maybe = split.replace(\"약\",\"\")\n",
        "        number = maybe.replace(\"건\",\"\")\n",
        "        nocom = number.replace(\",\",\"\")\n",
        "        num = int(nocom)\n",
        "        return(num)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00EpI2JyQXBC"
      },
      "source": [
        "#다음블로그에서 빈도 검색하는 함수\n",
        "def get_daum_frequency(x,y):\n",
        "    url = 'http://search.daum.net/search?nil_suggest=btn&w=blog&lpp=10&DA=STC&q={}&sd={}000000&ed={}235959&period=u&f=section&SA=daumsec'\n",
        "    make_start = pd.to_datetime(str(y), format='%Y%m%d')\n",
        "    make_end = make_start +timedelta(days=1)\n",
        "    z = make_end.strftime(\"%Y%m%d\")\n",
        "    \n",
        "    URL = url.format(x,y,z)\n",
        "    page = requests.get(URL)\n",
        "    time.sleep(1)\n",
        "    print(URL)\n",
        "    \n",
        "    soup = bs(page.text,'html.parser')\n",
        "    time.sleep(1)\n",
        "    \n",
        "    whole = soup.find('div',{'class':'sub_expander'})\n",
        "    find_number = whole.find('span',{'class':'txt_info'})\n",
        "    if find_number is None:\n",
        "        return(0)  \n",
        "    else:\n",
        "        found = find_number.text\n",
        "        split = found.split('/')[1]\n",
        "        maybe = split.replace(\"약\",\"\")\n",
        "        number = maybe.replace(\"건\",\"\")\n",
        "        nocom = number.replace(\",\",\"\")\n",
        "        num = int(nocom)\n",
        "        return(num)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUfyIGEXceyn"
      },
      "source": [
        "#네이버블로그에서 빈도 검색하는 함수\n",
        "def get_naver_frequency(x,y):\n",
        "    url = 'https://search.naver.com/search.naver?where=post&query={}&st=sim&sm=tab_opt&date_from={}&date_to={}&date_option=8&srchby=all&dup_remove=1&post_blogurl=&post_blogurl_without=&nso=so%3Ar%2Ca%3Aall%2Cp%3Afrom{}to{}'\n",
        "    make_start = pd.to_datetime(str(y))\n",
        "    make_end = make_start +timedelta(days=1)\n",
        "    z = make_end.strftime('%Y%m%d')\n",
        "\n",
        "    URL = url.format(x,y,z,y,z)\n",
        "    page = requests.get(URL)\n",
        "    time.sleep(1)\n",
        "\n",
        "    soup = bs(page.text,'html.parser')\n",
        "    content= soup.find('div',{'class':'blog section _blogBase _prs_blg'})\n",
        "    whole = content.find('div',{'class':'section_head'})\n",
        "    result = whole.find('span',{'class':'title_num'})\n",
        "\n",
        "    if result is None:\n",
        "        return(0)  \n",
        "    else:\n",
        "        found = result.text\n",
        "        split = found.split('/')[1]\n",
        "        maybe = split.replace(\"약\",\"\")\n",
        "        number = maybe.replace(\"건\",\"\")\n",
        "        nocom = number.replace(\",\",\"\")\n",
        "        num = int(nocom)\n",
        "        return(num)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVJ7dqHS2zzy"
      },
      "source": [
        "#네이버 되는지 안된는지 만든 테스트 코드_다음처럼 네이버블로그 홈페이지에서 크롤링하려니 API가 필요하대서 버리고...네이버 검색 후 블로그 섹션으로 들어가 검색\n",
        "def naver_test(x,y):\n",
        "    url = 'https://search.naver.com/search.naver?where=post&query={}&st=sim&sm=tab_opt&date_from={}&date_to={}&date_option=8&srchby=all&dup_remove=1&post_blogurl=&post_blogurl_without=&nso=so%3Ar%2Ca%3Aall%2Cp%3Afrom{}to{}'\n",
        "    make_start = pd.to_datetime(str(y))\n",
        "    make_end = make_start +timedelta(days=1)\n",
        "    z = make_end.strftime('%Y%m%d')\n",
        "\n",
        "    URL = url.format(x,y,z,y,z)\n",
        "    page = requests.get(URL)\n",
        "    time.sleep(1)\n",
        "\n",
        "    soup = bs(page.text,'html.parser')\n",
        "\n",
        "    content= soup.find('div',{'class':'blog section _blogBase _prs_blg'})\n",
        "    whole = content.find('div',{'class':'section_head'})\n",
        "    result = whole.find('span',{'class':'title_num'})\n",
        "\n",
        "    if result is None:\n",
        "        return(0)  \n",
        "    else:\n",
        "        found = result.text\n",
        "        split = found.split('/')[1]\n",
        "        maybe = split.replace(\"약\",\"\")\n",
        "        number = maybe.replace(\"건\",\"\")\n",
        "        nocom = number.replace(\",\",\"\")\n",
        "        num = int(nocom)\n",
        "        return(num)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDqd338RQXBG"
      },
      "source": [
        "#YYYYMMDD형식으로 날짜 리스트 만드는 함수 = 다음, 티스토리 검색용\n",
        "def get_date_in_line(year,month,day,x):\n",
        "    start_date = date(year,month,day)\n",
        "    day_list = []\n",
        "    for how_many in range(1,x+1):\n",
        "        formattedDate = start_date.strftime(\"%Y%m%d\")\n",
        "        day_list.append(formattedDate)\n",
        "        start_date += timedelta(days=1)\n",
        "    return(day_list)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6dbe3VFdkHN"
      },
      "source": [
        "#추가로 만든 YYYY-MM-DD형식으로 날짜 리스트 만드는 함수 \n",
        "def get_date_with_split(year,month,day,x):\n",
        "    start_date = date(year,month,day)\n",
        "    day_list = []\n",
        "    for how_many in range(1,x+1):\n",
        "      formattedDate = start_date.strftime('%Y-%m-%d')\n",
        "      day_list.append(formattedDate)\n",
        "      start_date += timedelta(days=1)\n",
        "    return(day_list)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUgyeUn9gAYI"
      },
      "source": [
        "### 4) 결과값 확인\n",
        "- start_list를 통해 다음블로그와 티스토리의 빈도수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5n9JeiNQXBJ"
      },
      "source": [
        "start_list = get_date_in_line(2018,7,8,365)\n",
        "start_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcIQC5VFQXBM"
      },
      "source": [
        "daum_frequency=[]\n",
        "\n",
        "for day in start_list:\n",
        "    start = int(day)\n",
        "    daum_frequency.append(get_daum_frequency('트러플',start))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8krBbPGQXBO"
      },
      "source": [
        "tistory_frequency=[]\n",
        "\n",
        "for day in start_list:\n",
        "    start = int(day)\n",
        "    tistory_frequency.append(get_tistory_frequency('트러플',start))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftsAqlyZQXBm"
      },
      "source": [
        "naver_frequency = []\n",
        "\n",
        "for day in start_list:\n",
        "  start = int(day)\n",
        "  naver_frequency.append(get_naver_frequency('트러플',start))"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r8Pywj5qnvs"
      },
      "source": [
        "### 5) 데이터프레임 생성 및 저장\n",
        "- 크롤링한 데이터를 바탕으로 데이터 프레임을 만들고 저장합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-IWd57IqWI0",
        "outputId": "ca5e4ac6-519a-467c-f068-fe346b98c077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "ROOT = '/content/drive'\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieEuNZJr0Hrh",
        "outputId": "cbe36e6d-e7e8-4e3f-9023-21016ee50543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd drive/'My Drive'/'아시아경제 유통팀'/'조사자료'"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/아시아경제 유통팀/조사자료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlKq8YKpD7Nw",
        "outputId": "9b1de1ee-02bb-403e-f426-2da735984009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'오프라인 년도별 비교'\u001b[0m/\n",
            "'전자상거래 이용 현황과 구매 행태 (1).pdf'\n",
            "'유통산업 현황 2019 및 2020 산업전망 보고서.pdf'\n",
            " 온라인으로_식품을_구매하는_장소_20200922182431.csv\n",
            "'2020년 7월 온라인쇼핑 동향.gdoc'\n",
            "'2020년 7월 온라인쇼핑 동향.pdf'\n",
            " 2020년만.pdf\n",
            " 산업통상자원부유통.csv\n",
            "'오프라인 카테고리 분석.pdf'\n",
            " Transaction_value_of_Online_shopping_mall_by_commodity_groups_coverage_for_goods_20200923102902.csv\n",
            " Transaction_value_of_Online_shopping_mall_by_commodity_groups_coverage_for_goods_20200923102902.gsheet\n",
            " 신한카드데이터.xlsx\n",
            " 국민카드데이터.xlsx\n",
            " 신용카드증가데이터.xlsx\n",
            " 트러플네이버리뷰빈도수.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxe-mButD8SI",
        "outputId": "bf7011b7-7dd4-49d8-9692-c255e392e0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "Blog_Frequency = pd.DataFrame({'Naver':naver_frequency,'Daum':daum_frequency,'Tistory':tistory_frequency},index=start_list)\n",
        "Blog_Frequency"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Naver</th>\n",
              "      <th>Daum</th>\n",
              "      <th>Tistory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20180708</th>\n",
              "      <td>249</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180709</th>\n",
              "      <td>276</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180710</th>\n",
              "      <td>254</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180711</th>\n",
              "      <td>226</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20180712</th>\n",
              "      <td>210</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20190703</th>\n",
              "      <td>501</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20190704</th>\n",
              "      <td>484</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20190705</th>\n",
              "      <td>385</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20190706</th>\n",
              "      <td>336</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20190707</th>\n",
              "      <td>469</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Naver  Daum  Tistory\n",
              "20180708    249     0        3\n",
              "20180709    276     1        4\n",
              "20180710    254     1        3\n",
              "20180711    226     2        2\n",
              "20180712    210     2        4\n",
              "...         ...   ...      ...\n",
              "20190703    501     0        3\n",
              "20190704    484     0        6\n",
              "20190705    385     0        6\n",
              "20190706    336     0        6\n",
              "20190707    469     2        6\n",
              "\n",
              "[365 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s90aHlj0EL9y",
        "outputId": "79eed971-df2b-4936-f631-30797f634054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "Blog_Frequency.to_csv('블로그리뷰.csv')\n",
        "files.download('블로그리뷰.csv')"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e855ccf0-564a-4e4e-b5a6-918c710bf83f\", \"\\ube14\\ub85c\\uadf8\\ub9ac\\ubdf0.csv\", 6282)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}